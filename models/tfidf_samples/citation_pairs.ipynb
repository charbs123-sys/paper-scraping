{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from pymongo import MongoClient\n",
    "import random\n",
    "from sentence_transformers import SentenceTransformer, InputExample, losses\n",
    "from torch.utils.data import DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mutual_citations = []\n",
    "\n",
    "# Convert citation_pairs to a set for faster lookups\n",
    "citation_set = set(citation_pairs)\n",
    "\n",
    "for source, cited in citation_pairs:\n",
    "    # Check if the reverse (cited, source) exists\n",
    "    if (cited, source) in citation_set:\n",
    "        mutual_citations.append((source, cited))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_duplicate_citations(doi_list):\n",
    "    for item in doi_list:\n",
    "        doi = item[0]  # The main DOI\n",
    "        citation_lists = item[1:]  # All citation lists\n",
    "\n",
    "        # Flatten the citation lists into a single list\n",
    "        all_citations = [citation for sublist in citation_lists for citation in sublist]\n",
    "\n",
    "        # Remove duplicates using a set\n",
    "        unique_citations = list(set(all_citations))\n",
    "\n",
    "        # Reconstruct the item with unique citations\n",
    "        item[1:] = [unique_citations]  # Replace all citation lists with a single list of unique citations\n",
    "\n",
    "    return doi_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cleaned_doi = remove_duplicate_citations(doi_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "positive_pairs = []\n",
    "\n",
    "for source, cited_dois in cleaned_doi:\n",
    "    for cited in cited_dois:\n",
    "        positive_pairs.append((source, cited))\n",
    "\n",
    "print(positive_pairs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_citations = []\n",
    "for source, citations in cleaned_doi:\n",
    "        for i in range(len(citations)):\n",
    "                all_citations.append(citations[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "negative_examples = []\n",
    "\n",
    "for source, citation in cleaned_doi:\n",
    "    negative_examples.append([source])\n",
    "    choices = []\n",
    "    for i in range(0, 10):\n",
    "        choice = random.choice(all_citations)\n",
    "        while choice in citation:\n",
    "            choice = random.choice(all_citations)\n",
    "        choices.append(choice)\n",
    "    negative_examples[-1].append(choices)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "negative_pairs = []\n",
    "for base, negative in negative_examples:\n",
    "    for negatives in negative:\n",
    "        negative_pairs.append((base, negatives))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_data = []\n",
    "for positive in positive_pairs:\n",
    "    training_data.append(InputExample(texts=[positive[0],positive[1]], label= 1))\n",
    "for negative in negative_pairs:\n",
    "    training_data.append(InputExample(texts=[negative[0],negative[1]], label= 0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = SentenceTransformer('all-MiniLM-L6-v2')\n",
    "model = model.to('cuda')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataloader = DataLoader(training_data, shuffle= True, batch_size= 32)\n",
    "train_loss = losses.CosineSimilarityLoss(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fit(train_objectives=[(train_dataloader, train_loss)], epochs= 5, warmup_steps=100, optimizer_params= {\"lr\": 2e-5}, output_path=\"./fine_tuned\", show_progress_bar= True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = SentenceTransformer(\"./fine_tuned\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
