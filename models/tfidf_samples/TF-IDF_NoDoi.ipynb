{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pymongo import MongoClient\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk import pos_tag\n",
    "import string\n",
    "from nltk.corpus import wordnet\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "import numpy as np\n",
    "import copy\n",
    "import pickle\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "summary = np.load(\"summary.npy\")\n",
    "original_summary = np.load(\"original.npy\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The user can input multiple things.\n",
    "1 - doi of the article they want to find (from doi we extract summary, preprocess then serves as input to vector) -- figure out how to query this later\n",
    "2 - summary of article (preprocess summary then find most similar article)\n",
    "3 - title if in db (use corresponding summary, preprocess then pass through model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If the user inputs the doi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#BASE_URL = 'http://export.arxiv.org/api/query?search_query=all:Machine%20Learning'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If the user inputs summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#user_input = test_data[-3][0] # Already preprocessed, but simply pass through function"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If the user inputs title:\n",
    "    - if title present in db get summary, preprocess then pass through model\n",
    "    - if title not present in db then preprocess title and pass through model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer = 'tfidf_vectorized.pkl'\n",
    "tfidf_model = 'tfidf.pkl'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "summary_full = [summary[index][0] for index in range(len(summary))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saved to cache\n"
     ]
    }
   ],
   "source": [
    "if os.path.exists(vectorizer) and os.path.exists(tfidf_model):\n",
    "    with open(vectorizer, \"rb\") as f:\n",
    "        tfidf_vectorizer = pickle.load(f)\n",
    "    with open(tfidf_model, \"rb\") as f:\n",
    "        tfidf_mat = pickle.load(f)\n",
    "else:\n",
    "    tfidf_vectorizer = TfidfVectorizer(lowercase=True, stop_words='english')\n",
    "    tfidf_mat = tfidf_vectorizer.fit_transform(summary_full)\n",
    "    with open(vectorizer, \"wb\") as f:\n",
    "        pickle.dump(tfidf_vectorizer, f)\n",
    "    with open(tfidf_model, \"wb\") as f:\n",
    "        pickle.dump(tfidf_mat, f)\n",
    "    print(\"saved to cache\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we get the user input to pass through model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_tfidf = tfidf_vectorizer.transform([summary_full[-1][0]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "similarities = cosine_similarity(new_tfidf, tfidf_mat)\n",
    "most_similar = similarities.argmax()\n",
    "score = similarities.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "similarities_np = np.array(similarities[0])\n",
    "highest = np.argpartition(similarities_np, -5)[-5:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We want to return the title for the objects with the 5 highest scores (this can be changed by the user)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_arr = np.array([[high, similarities_np[high]] for high in highest])\n",
    "clean_arr = clean_arr[clean_arr[:,1].argsort()][::-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "client = MongoClient(\"mongodb://localhost:27017/\")\n",
    "db = client[\"Arxiv\"]\n",
    "collection = db[\"Arxiv Papers\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is what we return to the user, namely, the title of the respective articles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "streaming adaptive nonparametric variational autoencoder \n",
      "\n",
      "using learned optimizers to make models robust to input noise \n",
      "\n",
      "risks from learned optimization in advanced machine learning systems \n",
      "\n",
      "sparsesense: human activity recognition from highly sparse sensor\n",
      "  data-streams using set-based neural networks \n",
      "\n",
      "self-supervised contrastive learning for eeg-based sleep staging \n",
      "\n"
     ]
    }
   ],
   "source": [
    "summary_top_5 = np.array(original_summary)[highest]\n",
    "for summarized in summary_top_5:\n",
    "    query = {\"summary\" : summarized[0]}\n",
    "    found = collection.find(query)\n",
    "    for document in found:\n",
    "        print(document['title'], \"\\n\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
