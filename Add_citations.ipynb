{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from pymongo import MongoClient\n",
    "import random\n",
    "from sentence_transformers import SentenceTransformer, InputExample, losses\n",
    "from torch.utils.data import DataLoader"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Connect to database and extract articles with a doi storing all unique doi in doi_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "client = MongoClient(\"mongodb://localhost:27017/\")\n",
    "db = client[\"Arxiv\"]\n",
    "collection = db[\"Arxiv Papers\"]\n",
    "\n",
    "query = {\"doi\": { \"$exists\": True, \"$ne\": None }}\n",
    "documents = collection.find(query, {\"doi\" : 1, \"_id\" : 0})\n",
    "doi_list = [[doc[\"doi\"]] for doc in documents]\n",
    "#doi_list = doi_list[0:10] #slicing to reduce computational expensiveness"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Add citings to mongodb database - perform error checking, was not able to extract citings for all doi's"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "index = 0\n",
    "for doi in doi_list:\n",
    "    doi = doi[0]\n",
    "    query = {\"doi\" : doi}\n",
    "    print(index)\n",
    "    url = f\"https://opencitations.net/index/coci/api/v1/citations/{doi}\"\n",
    "    response = requests.get(url).json()\n",
    "    arr = [citing[\"citing\"] for citing in response]\n",
    "    update = {\"$set\": {\"citings\" : arr}}\n",
    "    collection.update_one(query, update)\n",
    "    doi_list[index].append(arr)\n",
    "    index += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#errors in adding citings, simply ignoring this for model\n",
    "doi_list = doi_list[0:635]\n",
    "doi_list = doi_list[0:len(doi_list) - 2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using mutual citations does not work since they are limited"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract all unique DOIs in the dataset\n",
    "all_dois = {entry[0] for entry in doi_list}\n",
    "citation_pairs = []\n",
    "index = 0\n",
    "for entry in doi_list:\n",
    "    print(index)\n",
    "    index += 1\n",
    "    source_doi = entry[0]\n",
    "    cited_dois = entry[1]\n",
    "    \n",
    "    for cited_doi in cited_dois:\n",
    "        # Only include citations where the cited DOI exists in the dataset\n",
    "        if cited_doi in all_dois:\n",
    "            citation_pairs.append((source_doi, cited_doi))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "mutual_citations = []\n",
    "\n",
    "# Convert citation_pairs to a set for faster lookups\n",
    "citation_set = set(citation_pairs)\n",
    "\n",
    "for source, cited in citation_pairs:\n",
    "    # Check if the reverse (cited, source) exists\n",
    "    if (cited, source) in citation_set:\n",
    "        mutual_citations.append((source, cited))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Relationships based on direction citations, co-citations or shared references may be better"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_duplicate_citations(doi_list):\n",
    "    for item in doi_list:\n",
    "        doi = item[0]  # The main DOI\n",
    "        citation_lists = item[1:]  # All citation lists\n",
    "\n",
    "        # Flatten the citation lists into a single list\n",
    "        all_citations = [citation for sublist in citation_lists for citation in sublist]\n",
    "\n",
    "        # Remove duplicates using a set\n",
    "        unique_citations = list(set(all_citations))\n",
    "\n",
    "        # Reconstruct the item with unique citations\n",
    "        item[1:] = [unique_citations]  # Replace all citation lists with a single list of unique citations\n",
    "\n",
    "    return doi_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "cleaned_doi = remove_duplicate_citations(doi_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "positive_pairs = []\n",
    "\n",
    "for source, cited_dois in cleaned_doi:\n",
    "    for cited in cited_dois:\n",
    "        positive_pairs.append((source, cited))\n",
    "\n",
    "print(positive_pairs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train model based on these positive pairs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First we generate negative pairs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_citations = []\n",
    "for source, citations in cleaned_doi:\n",
    "        for i in range(len(citations)):\n",
    "                all_citations.append(citations[i])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "negative_examples = []\n",
    "\n",
    "for source, citation in cleaned_doi:\n",
    "    negative_examples.append([source])\n",
    "    choices = []\n",
    "    for i in range(0, 10):\n",
    "        choice = random.choice(all_citations)\n",
    "        while choice in citation:\n",
    "            choice = random.choice(all_citations)\n",
    "        choices.append(choice)\n",
    "    negative_examples[-1].append(choices)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "negative_pairs = []\n",
    "for base, negative in negative_examples:\n",
    "    for negatives in negative:\n",
    "        negative_pairs.append((base, negatives))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_data = []\n",
    "for positive in positive_pairs:\n",
    "    training_data.append(InputExample(texts=[positive[0],positive[1]], label= 1))\n",
    "for negative in negative_pairs:\n",
    "    training_data.append(InputExample(texts=[negative[0],negative[1]], label= 0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = SentenceTransformer('all-MiniLM-L6-v2')\n",
    "model = model.to('cuda')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataloader = DataLoader(training_data, shuffle= True, batch_size= 32)\n",
    "train_loss = losses.CosineSimilarityLoss(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we fine-tune the model accordingly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fit(train_objectives=[(train_dataloader, train_loss)], epochs= 5, warmup_steps=100, optimizer_params= {\"lr\": 2e-5}, output_path=\"./fine_tuned\", show_progress_bar= True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can vindicate performance using InformationRetrievalEvaluator, after this we use the model to change the embeddings of each arxiv article"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After changing the embeddings we push this into the recommendation pipeline (start with something simple like KNN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = SentenceTransformer(\"./fine_tuned\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
